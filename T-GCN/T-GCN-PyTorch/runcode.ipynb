{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (3.3.3)\n",
      "Collecting pytorch-lightning>=1.3.0\n",
      "  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
      "\u001b[K     |████████████████████████████████| 527 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (20.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (3.7.4.3)\n",
      "Collecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 881.9 MB 33 kB/s s eta 0:00:01     |████████████▍                   | 342.0 MB 11.7 MB/s eta 0:00:46\n",
      "\u001b[?25hCollecting torchmetrics>=0.3.0\n",
      "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
      "\u001b[K     |████████████████████████████████| 409 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future>=0.17.1\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[K     |████████████████████████████████| 840 kB 7.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=17.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (2.4.7)\n",
      "Collecting PyYAML>=5.1\n",
      "  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n",
      "\u001b[K     |████████████████████████████████| 603 kB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (3.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (0.30.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (1.34.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (3.3.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (1.11.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.2-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (3.3.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 3.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (2.6)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 2)) (8.1.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 50 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[K     |████████████████████████████████| 502 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-0.20.0-py3-none-any.whl (17 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 8.2 MB/s eta 0:00:012\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (946 kB)\n",
      "\u001b[K     |████████████████████████████████| 946 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (20.3.0)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 11.1 MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.0->-r requirements.txt (line 5)) (3.4.0)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001b[K     |████████████████████████████████| 952 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: future, idna-ssl\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=494240 sha256=9e239842e5319c2886a049bf28f164f5d46cf0520d5486dbd900b345a0d7c001\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/f1/0c/e56d12b3804345ce5ba34279cbfe583ecafdd1401551457330\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3949 sha256=33cb87ae187f76342dd2d499592158666241c32e4723333a87d010c933fb473b\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "Successfully built future idna-ssl\n",
      "Installing collected packages: urllib3, pyasn1, charset-normalizer, certifi, rsa, requests, pyasn1-modules, oauthlib, multidict, frozenlist, cachetools, yarl, requests-oauthlib, idna-ssl, google-auth, dataclasses, asynctest, async-timeout, aiosignal, torch, tensorboard-plugin-wit, tensorboard-data-server, setuptools, pyDeprecate, importlib-resources, google-auth-oauthlib, fsspec, aiohttp, tqdm, torchmetrics, tensorboard, PyYAML, pytz, future, scipy, pytorch-lightning, python-dotenv, pandas\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 51.1.1\n",
      "    Uninstalling setuptools-51.1.1:\n",
      "      Successfully uninstalled setuptools-51.1.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 1.15.5 requires tensorboard<1.16.0,>=1.15.0, but you have tensorboard 2.10.1 which is incompatible.\u001b[0m\n",
      "Successfully installed PyYAML-6.0 aiohttp-3.8.4 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 cachetools-4.2.4 certifi-2022.12.7 charset-normalizer-2.0.12 dataclasses-0.8 frozenlist-1.2.0 fsspec-2022.1.0 future-0.18.3 google-auth-2.17.2 google-auth-oauthlib-0.4.6 idna-ssl-1.1.0 importlib-resources-5.4.0 multidict-5.2.0 oauthlib-3.2.2 pandas-1.1.5 pyDeprecate-0.3.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 python-dotenv-0.20.0 pytorch-lightning-1.5.10 pytz-2023.3 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.5.4 setuptools-59.5.0 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.10.2 torchmetrics-0.8.2 tqdm-4.64.1 urllib3-1.26.15 yarl-1.7.2\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !python main.py --model_name TGCN \\\n",
    "--max_epochs 2 \\\n",
    "--learning_rate 0.001 \\\n",
    "--weight_decay 0 \\\n",
    "--batch_size 64 \\\n",
    "--hidden_dim 64 \\\n",
    "--settings supervised \\\n",
    "--loss \"mse_with_regularizer\" \\\n",
    "--data PEMS04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"GRU\", \"LSTM\", \"GCN\", \"TGCN\",\"TGCN_LSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: PEMS08  Loss: mse_with_regularizer  Model: GRU\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen,PIPE\n",
    "model = [\"GRU\"]\n",
    "max_epochs = \"100\"\n",
    "learning_rate = \"0.001\" \n",
    "weight_decay =\"0\"\n",
    "enable_progress_bar = \"False\"\n",
    "batch_size = \"64\"\n",
    "hidden_dim = \"64\"\n",
    "cell_dim = \"64\"\n",
    "dropout = \"0\"\n",
    "layer_2 = [\"False\"]\n",
    "loss = [\"mse_with_regularizer\",\"mse_with_regularizer_l1\",\"mse_with_regularizer_entropy\",\"mse\"]\n",
    "data = [\"PEMS08\",\"PEMS04\",\"losloop\",\"shenzhen\"]\n",
    "gpus = \"0\"\n",
    "for i in data:\n",
    "    for j in loss:\n",
    "        for k in model:\n",
    "            for l in layer_2:\n",
    "                print(\"Dataset:\",i,\" Loss:\",j,\" Model:\",k,\"Layer 2:\",l)\n",
    "                cmd_str = [\"python\",\n",
    "                       \"main.py\",\n",
    "                       \"--enable_progress_bar\",enable_progress_bar,\n",
    "                       \"--model_name\",k,\n",
    "                       \"--max_epochs\",max_epochs,\n",
    "                       \"--learning_rate\",learning_rate,\n",
    "                       \"--weight_decay\",weight_decay,\n",
    "                       \"--batch_size\",batch_size,\n",
    "                       \"--hidden_dim\",hidden_dim,\n",
    "                       \"--cell_dim\",hidden_dim,\n",
    "                       \"--dropout\",dropout,\n",
    "                       \"--loss\",j,\n",
    "                       \"--layer_2\",layer_2[1],\n",
    "                       \"--data\",i,\n",
    "                       \"--gpus\",gpus,\n",
    "                      ]\n",
    "                p = Popen(cmd_str,stdout=PIPE)\n",
    "                for m in p.stdout:\n",
    "                    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[2023-04-07 11:35:20,305 INFO]\u001b[0m{'logger': True, 'checkpoint_callback': None, 'enable_checkpointing': True, 'default_root_dir': None, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'process_position': 0, 'num_nodes': 1, 'num_processes': 1, 'devices': None, 'gpus': None, 'auto_select_gpus': False, 'tpu_cores': None, 'ipus': None, 'log_gpu_memory': None, 'progress_bar_refresh_rate': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 1, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': 5, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': 1.0, 'limit_val_batches': 1.0, 'limit_test_batches': 1.0, 'limit_predict_batches': 1.0, 'val_check_interval': 1.0, 'flush_logs_every_n_steps': None, 'log_every_n_steps': 50, 'accelerator': None, 'strategy': None, 'sync_batchnorm': False, 'precision': 32, 'enable_model_summary': True, 'weights_summary': 'top', 'weights_save_path': None, 'num_sanity_val_steps': 2, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': False, 'deterministic': False, 'reload_dataloaders_every_n_epochs': 0, 'reload_dataloaders_every_epoch': False, 'auto_lr_find': False, 'replace_sampler_ddp': True, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'prepare_data_per_node': None, 'plugins': None, 'amp_backend': 'native', 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'stochastic_weight_avg': False, 'terminate_on_nan': None, 'data': 'losloop', 'model_name': 'TGCN', 'settings': 'supervised', 'log_path': None, 'send_email': False, 'batch_size': 32, 'seq_len': 12, 'pre_len': 3, 'split_ratio': 0.8, 'normalize': True, 'hidden_dim': 64, 'dropout': 0.0, 'cell_dim': 64, 'layer_2': True, 'learning_rate': 0.001, 'weight_decay': 0.0, 'loss': 'mse_with_regularizer'}\n",
      "\u001b[31m[2023-04-07 11:35:20,386 INFO]\u001b[0mGPU available: False, used: False\n",
      "\u001b[31m[2023-04-07 11:35:20,386 INFO]\u001b[0mTPU available: False, using: 0 TPU cores\n",
      "\u001b[31m[2023-04-07 11:35:20,386 INFO]\u001b[0mIPU available: False, using: 0 IPUs\n",
      "\u001b[31m[2023-04-07 11:35:22,450 INFO]\u001b[0m\n",
      "  | Name      | Type   | Params\n",
      "-------------------------------------\n",
      "0 | model     | TGCN   | 12.7 K\n",
      "1 | regressor | Linear | 195   \n",
      "-------------------------------------\n",
      "12.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.9 K    Total params\n",
      "0.051     Total estimated model params size (MB)\n",
      "Epoch 0:  98%|█████████████▋| 50/51 [00:29<00:00,  1.71it/s, loss=0.38, v_num=8]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████████| 51/51 [00:32<00:00,  1.57it/s, loss=0.38, v_num=8]\u001b[A\n",
      "Epoch 1:  98%|████████████▋| 50/51 [00:35<00:00,  1.42it/s, loss=0.298, v_num=8]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████████| 51/51 [00:38<00:00,  1.32it/s, loss=0.298, v_num=8]\u001b[A\n",
      "Epoch 2:  98%|████████████▋| 50/51 [00:36<00:00,  1.38it/s, loss=0.253, v_num=8]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████████| 51/51 [00:39<00:00,  1.29it/s, loss=0.253, v_num=8]\u001b[A\n",
      "Epoch 3:  98%|████████████▋| 50/51 [00:33<00:00,  1.48it/s, loss=0.221, v_num=8]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████████| 51/51 [00:37<00:00,  1.37it/s, loss=0.221, v_num=8]\u001b[A\n",
      "Epoch 4:  98%|████████████▋| 50/51 [00:34<00:00,  1.43it/s, loss=0.196, v_num=8]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████████| 51/51 [00:38<00:00,  1.33it/s, loss=0.196, v_num=8]\u001b[A\n",
      "Epoch 4: 100%|█████████████| 51/51 [00:38<00:00,  1.33it/s, loss=0.196, v_num=8]\u001b[A\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py:1399: UserWarning: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `validate(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  f\"`.{fn}(ckpt_path=None)` was called without a model.\"\n",
      "\u001b[31m[2023-04-07 11:39:26,731 INFO]\u001b[0mRestoring states from the checkpoint path at /tf/notebooks/T-GCN/T-GCN/T-GCN-PyTorch/lightning_logs/version_8/checkpoints/epoch=4-step=249.ckpt\n",
      "\u001b[31m[2023-04-07 11:39:26,740 INFO]\u001b[0mLoaded model weights from checkpoint at /tf/notebooks/T-GCN/T-GCN/T-GCN-PyTorch/lightning_logs/version_8/checkpoints/epoch=4-step=249.ckpt\n",
      "Validating: 100%|█████████████████████████████████| 1/1 [00:03<00:00,  3.43s/it]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'ExplainedVar': 0.39125776290893555,\n",
      " 'MAE': 7.723293304443359,\n",
      " 'R2': 0.390529990196228,\n",
      " 'RMSE': 10.838318824768066,\n",
      " 'accuracy': 0.8154897093772888,\n",
      " 'val_loss': 117.64105987548828}\n",
      "--------------------------------------------------------------------------------\n",
      "Validating: 100%|█████████████████████████████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "CPU times: user 3.22 s, sys: 794 ms, total: 4.01 s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python main.py --model_name TGCN \\\n",
    "--max_epochs 5 \\\n",
    "--learning_rate 0.001 \\\n",
    "--weight_decay 0 \\\n",
    "--batch_size 32 \\\n",
    "--hidden_dim 64 \\\n",
    "--settings supervised \\\n",
    "--loss \"mse_with_regularizer\" \\\n",
    "--layer_2 False \\\n",
    "--dropout 0 \\\n",
    "--data losloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU times: user 3.22 s, sys: 794 ms, total: 4.01 s\n",
    "Wall time: 4min 11s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --model_name GRU \\\n",
    "--max_epochs 10 \\\n",
    "--learning_rate 0.001 \\\n",
    "--weight_decay 0 \\\n",
    "--batch_size 64 \\\n",
    "--hidden_dim 8 \\\n",
    "--settings supervised \\\n",
    "--data PEMS04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --model_name LSTM \\\n",
    "--max_epochs 1 \\\n",
    "--learning_rate 0.001 \\\n",
    "--weight_decay 0 \\\n",
    "--batch_size 64 \\\n",
    "--hidden_dim 8 \\\n",
    "--cell_dim 12 \\\n",
    "--settings supervised \\\n",
    "--data PEMS04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TGCN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --model_name TGCN_LSTM \\\n",
    "--max_epochs 20 \\\n",
    "--learning_rate 0.001 \\\n",
    "--weight_decay 0 \\\n",
    "--batch_size 64 \\\n",
    "--hidden_dim 8 \\\n",
    "--cell_dim 64 \\\n",
    "--settings supervised \\\n",
    "--data losloop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17856, 170])\n",
      "19.872730016708374\n",
      "19.825145483016968\n",
      "tensor(6.3904e+12, dtype=torch.float64)\n",
      "svd s u v =  torch.Size([170, 17856])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import time\n",
    "\n",
    "def svd_low_rank_approximation(matrix, k):\n",
    "    # Perform SVD on the matrix\n",
    "    \n",
    "    u, s, v = torch.svd(matrix)\n",
    "    \n",
    "    # Truncate the singular values and matrices to rank k\n",
    "    s_k = s[:k]\n",
    "    u_k = u[:, :k]\n",
    "    v_k = v[:, :k]\n",
    "    \n",
    "    \n",
    "    return (s_k,u_k,v_k)\n",
    "\n",
    "def adjmat(adj):\n",
    "    return torch.mm(torch.mm(adj[1], torch.diag(adj[0])), adj[2].t())\n",
    "\n",
    "PEMS08_adj = pd.read_csv(r'data/pems08_adj.csv',header=None)\n",
    "adj = np.array(PEMS08_adj)\n",
    "adj = torch.tensor(adj)\n",
    "\n",
    "data = np.load(\"data/pems08.npz\")\n",
    "data = data.f.data\n",
    "df_data = pd.DataFrame(data[:,:,0])\n",
    "df_data = df_data.values.tolist()\n",
    "feat = np.array(df_data, dtype=np.float32)\n",
    "feat = torch.tensor(feat)\n",
    "print(feat.shape)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    adjsvd= svd_low_rank_approximation(feat.t(), 10000)\n",
    "    adjmatrix= adjmat(adjsvd)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    adjsvd= svd_low_rank_approximation(feat.t(),17856)\n",
    "    adjmatrix= adjmat(adjsvd)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(adjmatrix.sum()**2/adj.sum()**2)\n",
    "print(\"svd s u v = \",adjmatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      " [[21299.84727986 18898.13165904 12943.61253019 ... 13181.69580527\n",
      "  17710.40767453  2033.24825426]\n",
      " [18898.13165904 23412.79781435 15126.26361152 ... 14584.91752615\n",
      "  16745.71635712  2402.4195232 ]\n",
      " [12943.61253019 15126.26361152 12876.44453819 ...  9731.1222134\n",
      "  11263.29372559  1705.03653584]\n",
      " ...\n",
      " [13181.69580527 14584.91752615  9731.1222134  ... 10660.86941215\n",
      "  11847.14031209  1574.06524126]\n",
      " [17710.40767453 16745.71635712 11263.29372559 ... 11847.14031209\n",
      "  17624.32361205  1766.11560189]\n",
      " [ 2033.24825426  2402.4195232   1705.03653584 ...  1574.06524126\n",
      "   1766.11560189   331.49667177]]\n",
      "l = \n",
      " [ 1.72126341e+06+0.00000000e+00j  1.09668122e+05+0.00000000e+00j\n",
      "  2.93000710e+04+0.00000000e+00j  2.03012635e+04+0.00000000e+00j\n",
      "  1.93070108e+04+0.00000000e+00j  1.41062700e+04+0.00000000e+00j\n",
      "  1.36642991e+04+0.00000000e+00j  1.19265608e+04+0.00000000e+00j\n",
      "  1.07811271e+04+0.00000000e+00j  9.41204786e+03+0.00000000e+00j\n",
      "  8.52796785e+03+0.00000000e+00j  7.67032353e+03+0.00000000e+00j\n",
      "  6.61597500e+03+0.00000000e+00j  6.44555068e+03+0.00000000e+00j\n",
      "  4.93945952e+03+0.00000000e+00j  4.56826388e+03+0.00000000e+00j\n",
      "  4.42818841e+03+0.00000000e+00j  3.76583668e+03+0.00000000e+00j\n",
      "  3.59632826e+03+0.00000000e+00j  3.24585364e+03+0.00000000e+00j\n",
      "  3.11263736e+03+0.00000000e+00j  2.77025415e+03+0.00000000e+00j\n",
      "  2.69469129e+03+0.00000000e+00j  2.48158885e+03+0.00000000e+00j\n",
      "  2.43159309e+03+0.00000000e+00j  2.33864983e+03+0.00000000e+00j\n",
      "  2.29644282e+03+0.00000000e+00j  2.22725861e+03+0.00000000e+00j\n",
      "  2.09654890e+03+0.00000000e+00j  1.97858965e+03+0.00000000e+00j\n",
      "  1.84446411e+03+0.00000000e+00j  1.72798604e+03+0.00000000e+00j\n",
      "  1.69870742e+03+0.00000000e+00j  1.67259432e+03+0.00000000e+00j\n",
      "  1.55516064e+03+0.00000000e+00j  1.52657018e+03+0.00000000e+00j\n",
      "  1.49857794e+03+0.00000000e+00j  1.39871570e+03+0.00000000e+00j\n",
      "  1.39322181e+03+0.00000000e+00j  1.30059393e+03+0.00000000e+00j\n",
      "  1.25040384e+03+0.00000000e+00j  1.22181447e+03+0.00000000e+00j\n",
      "  1.19912403e+03+0.00000000e+00j  1.14852111e+03+0.00000000e+00j\n",
      "  1.13784696e+03+0.00000000e+00j  1.12069788e+03+0.00000000e+00j\n",
      "  1.06440166e+03+0.00000000e+00j  1.03268609e+03+0.00000000e+00j\n",
      "  9.88759342e+02+0.00000000e+00j  9.68746219e+02+0.00000000e+00j\n",
      "  9.44871902e+02+0.00000000e+00j  9.39339214e+02+0.00000000e+00j\n",
      "  9.06260400e+02+0.00000000e+00j  8.99476946e+02+0.00000000e+00j\n",
      "  8.73074316e+02+0.00000000e+00j  8.55798920e+02+0.00000000e+00j\n",
      "  8.34047380e+02+0.00000000e+00j  8.14635442e+02+0.00000000e+00j\n",
      "  8.01172612e+02+0.00000000e+00j  7.87203126e+02+0.00000000e+00j\n",
      "  7.78945299e+02+0.00000000e+00j  7.59239920e+02+0.00000000e+00j\n",
      "  7.48202087e+02+0.00000000e+00j  7.29616156e+02+0.00000000e+00j\n",
      "  7.17155479e+02+0.00000000e+00j  6.96683050e+02+0.00000000e+00j\n",
      "  6.88618889e+02+0.00000000e+00j  6.79558036e+02+0.00000000e+00j\n",
      "  6.57880450e+02+0.00000000e+00j  6.43293654e+02+0.00000000e+00j\n",
      "  6.29470935e+02+0.00000000e+00j  6.25031806e+02+0.00000000e+00j\n",
      "  6.08956119e+02+0.00000000e+00j  5.85457288e+02+0.00000000e+00j\n",
      "  5.73994212e+02+0.00000000e+00j  5.63356567e+02+0.00000000e+00j\n",
      "  5.50190541e+02+0.00000000e+00j  5.34108515e+02+0.00000000e+00j\n",
      "  5.29840004e+02+0.00000000e+00j  5.11515568e+02+0.00000000e+00j\n",
      "  5.07446225e+02+0.00000000e+00j  4.97804873e+02+0.00000000e+00j\n",
      "  4.89811927e+02+0.00000000e+00j  4.82292329e+02+0.00000000e+00j\n",
      "  4.74551546e+02+0.00000000e+00j  4.58958924e+02+0.00000000e+00j\n",
      "  4.46179904e+02+0.00000000e+00j  4.24619855e+02+0.00000000e+00j\n",
      "  4.18665929e+02+0.00000000e+00j  4.17238203e+02+0.00000000e+00j\n",
      "  4.07810587e+02+0.00000000e+00j  3.98718259e+02+0.00000000e+00j\n",
      "  3.91494815e+02+0.00000000e+00j  3.81822454e+02+0.00000000e+00j\n",
      "  3.78123681e+02+0.00000000e+00j  3.71964861e+02+0.00000000e+00j\n",
      "  3.63093456e+02+0.00000000e+00j  3.52659496e+02+0.00000000e+00j\n",
      "  3.48912515e+02+0.00000000e+00j  3.43336551e+02+0.00000000e+00j\n",
      "  3.35630909e+02+0.00000000e+00j  3.31695596e+02+0.00000000e+00j\n",
      "  3.26313004e+02+0.00000000e+00j  3.15664011e+02+0.00000000e+00j\n",
      "  2.99296901e+02+0.00000000e+00j  2.90908577e+02+0.00000000e+00j\n",
      "  2.89241672e+02+0.00000000e+00j  2.77558614e+02+0.00000000e+00j\n",
      "  2.74426106e+02+0.00000000e+00j  2.66438139e+02+0.00000000e+00j\n",
      "  2.61564893e+02+0.00000000e+00j  2.52526413e+02+0.00000000e+00j\n",
      "  2.38754499e+02+0.00000000e+00j  2.37401381e+02+0.00000000e+00j\n",
      "  2.32743408e+02+0.00000000e+00j  2.24555534e+02+0.00000000e+00j\n",
      "  2.22172897e+02+0.00000000e+00j  2.15035820e+02+0.00000000e+00j\n",
      "  2.11020338e+02+0.00000000e+00j  2.04773048e+02+0.00000000e+00j\n",
      "  1.93507895e+02+0.00000000e+00j  1.90103909e+02+0.00000000e+00j\n",
      "  1.85231036e+02+0.00000000e+00j  1.82294192e+02+0.00000000e+00j\n",
      "  1.61551694e+02+0.00000000e+00j  1.59566843e+02+0.00000000e+00j\n",
      "  1.58174219e+02+0.00000000e+00j  1.50099315e+02+0.00000000e+00j\n",
      "  1.48229946e+02+0.00000000e+00j  1.30353675e+02+0.00000000e+00j\n",
      "  1.21885717e+02+0.00000000e+00j  1.19744770e+02+0.00000000e+00j\n",
      "  1.13484852e+02+0.00000000e+00j  1.08196149e+02+0.00000000e+00j\n",
      "  8.24141622e+01+0.00000000e+00j  7.48390364e+01+0.00000000e+00j\n",
      "  6.07741419e+01+0.00000000e+00j  5.56913271e+01+0.00000000e+00j\n",
      "  5.40865814e+01+0.00000000e+00j  5.03445738e+01+0.00000000e+00j\n",
      "  3.80745686e+01+0.00000000e+00j  1.65837478e+01+0.00000000e+00j\n",
      "  1.00235455e+01+0.00000000e+00j  9.49954752e+00+0.00000000e+00j\n",
      "  6.26023078e+00+0.00000000e+00j  2.31124259e+00+0.00000000e+00j\n",
      "  1.38849265e+00+0.00000000e+00j  1.75727096e-01+0.00000000e+00j\n",
      "  5.40271408e-02+0.00000000e+00j  2.42260138e-13+0.00000000e+00j\n",
      "  1.76818871e-13+2.01021885e-14j  1.76818871e-13-2.01021885e-14j\n",
      "  1.38510080e-13+0.00000000e+00j  1.17322034e-13+4.34174735e-14j\n",
      "  1.17322034e-13-4.34174735e-14j  9.03488478e-14+0.00000000e+00j\n",
      "  4.00279958e-14+3.48521018e-14j  4.00279958e-14-3.48521018e-14j\n",
      "  1.76738600e-14+0.00000000e+00j  5.89504315e-15+2.90347168e-14j\n",
      "  5.89504315e-15-2.90347168e-14j -1.28220469e-14+7.70118888e-14j\n",
      " -1.28220469e-14-7.70118888e-14j -1.37665006e-14+4.73241891e-15j\n",
      " -1.37665006e-14-4.73241891e-15j -3.65927243e-14+1.84594464e-14j\n",
      " -3.65927243e-14-1.84594464e-14j -6.48844729e-14+2.00639649e-14j\n",
      " -6.48844729e-14-2.00639649e-14j -1.34653367e-13+0.00000000e+00j]\n",
      "V = \n",
      " [[-1.03157486e-01+0.00000000e+00j -8.34418035e-02+0.00000000e+00j\n",
      "  -2.03836884e-02+0.00000000e+00j ... -1.95063961e-17-1.00895854e-17j\n",
      "  -1.95063961e-17+1.00895854e-17j  1.47154634e-17+0.00000000e+00j]\n",
      " [-1.10548578e-01+0.00000000e+00j  7.54943444e-02+0.00000000e+00j\n",
      "  -1.96857692e-02+0.00000000e+00j ...  1.31968192e-16+2.42950002e-17j\n",
      "   1.31968192e-16-2.42950002e-17j -6.46162659e-17+0.00000000e+00j]\n",
      " [-7.51624752e-02+0.00000000e+00j  6.43812417e-02+0.00000000e+00j\n",
      "  -2.02511529e-02+0.00000000e+00j ... -3.61676557e-17-4.04857481e-17j\n",
      "  -3.61676557e-17+4.04857481e-17j -5.71642994e-17+0.00000000e+00j]\n",
      " ...\n",
      " [-7.49841180e-02+0.00000000e+00j  4.91847195e-03+0.00000000e+00j\n",
      "  -2.61882765e-02+0.00000000e+00j ... -8.93095057e-18-1.92808417e-17j\n",
      "  -8.93095057e-18+1.92808417e-17j  1.09164973e-16+0.00000000e+00j]\n",
      " [-9.31411825e-02+0.00000000e+00j -1.00564240e-01+0.00000000e+00j\n",
      "   1.29903953e-02+0.00000000e+00j ... -3.39631159e-17-2.57876260e-17j\n",
      "  -3.39631159e-17+2.57876260e-17j  4.25955270e-17+0.00000000e+00j]\n",
      " [-1.20835021e-02+0.00000000e+00j  1.16097228e-02+0.00000000e+00j\n",
      "   7.09483174e-03+0.00000000e+00j ...  2.06986375e-16-3.62773642e-17j\n",
      "   2.06986375e-16+3.62773642e-17j -3.70505518e-17+0.00000000e+00j]]\n",
      "Y = \n",
      " [[ 1.70001764e+03+0.00000000e+00j  2.21297183e+02+0.00000000e+00j\n",
      "   5.99614697e+01+0.00000000e+00j ...  1.13686838e-13+1.24344979e-13j\n",
      "   1.13686838e-13-1.24344979e-13j -4.26325641e-14+0.00000000e+00j]\n",
      " [ 1.71643521e+03+0.00000000e+00j  2.12418295e+02+0.00000000e+00j\n",
      "   5.07610452e+01+0.00000000e+00j ... -1.98951966e-13-9.94759830e-14j\n",
      "  -1.98951966e-13+9.94759830e-14j  1.42108547e-13+0.00000000e+00j]\n",
      " [ 1.72680919e+03+0.00000000e+00j  1.96560515e+02+0.00000000e+00j\n",
      "   3.50081100e+01+0.00000000e+00j ... -5.68434189e-14-2.48689958e-14j\n",
      "  -5.68434189e-14+2.48689958e-14j  1.42108547e-14+0.00000000e+00j]\n",
      " ...\n",
      " [ 1.75393049e+03+0.00000000e+00j  2.26605287e+02+0.00000000e+00j\n",
      "  -1.05582351e+02+0.00000000e+00j ... -2.27373675e-13-1.59872116e-13j\n",
      "  -2.27373675e-13+1.59872116e-13j  1.42108547e-13+0.00000000e+00j]\n",
      " [ 1.81827904e+03+0.00000000e+00j  2.18667890e+02+0.00000000e+00j\n",
      "  -8.24282373e+01+0.00000000e+00j ...  1.42108547e-13+1.06581410e-14j\n",
      "   1.42108547e-13-1.06581410e-14j -1.27897692e-13+0.00000000e+00j]\n",
      " [ 1.86447124e+03+0.00000000e+00j  2.38172159e+02+0.00000000e+00j\n",
      "  -8.31680608e+01+0.00000000e+00j ... -1.98951966e-13-7.46069873e-14j\n",
      "  -1.98951966e-13+7.46069873e-14j  8.52651283e-14+0.00000000e+00j]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-fcf2e6dcdd53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# 1) then columns of V are principal directions/axes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflip_signs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprincipal_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# 2) columns of US are principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def flip_signs(A, B):\n",
    "    \"\"\"\n",
    "    utility function for resolving the sign ambiguity in SVD\n",
    "    http://stats.stackexchange.com/q/34396/115202\n",
    "    \"\"\"\n",
    "    signs = np.sign(A) * np.sign(B)\n",
    "    return A, B * signs\n",
    "\n",
    "\n",
    "# Let the data matrix X be of n x p size,\n",
    "# where n is the number of samples and p is the number of variables\n",
    "n, p = 10, 170\n",
    "data = np.load(\"data/pems08.npz\")\n",
    "data = data.f.data\n",
    "df_data = pd.DataFrame(data[:,:,0])\n",
    "df_data = df_data.values.tolist()\n",
    "X = np.array(df_data, dtype=np.float32)\n",
    "X -= np.mean(X,axis=0)\n",
    "\n",
    "# the p x p covariance matrix\n",
    "C = np.cov(X, rowvar=False)\n",
    "print(\"C = \\n\", C)\n",
    "# C is a symmetric matrix and so it can be diagonalized:\n",
    "l, principal_axes = la.eig(C)\n",
    "# sort results wrt. eigenvalues\n",
    "idx = l.argsort()[::-1]\n",
    "l, principal_axes = l[idx], principal_axes[:, idx]\n",
    "# the eigenvalues in decreasing order\n",
    "print(\"l = \\n\", l)\n",
    "# a matrix of eigenvectors (each column is an eigenvector)\n",
    "print(\"V = \\n\", principal_axes)\n",
    "# projections of X on the principal axes are called principal components\n",
    "principal_components = X.dot(principal_axes)\n",
    "print(\"Y = \\n\", principal_components)\n",
    "\n",
    "# we now perform singular value decomposition of X\n",
    "# \"economy size\" (or \"thin\") SVD\n",
    "U, s, Vt = la.svd(X, full_matrices=False)\n",
    "V = Vt.T\n",
    "S = np.diag(s)\n",
    "\n",
    "# 1) then columns of V are principal directions/axes.\n",
    "assert np.allclose(*flip_signs(V, principal_axes))\n",
    "\n",
    "# 2) columns of US are principal components\n",
    "assert np.allclose(*flip_signs(U.dot(S), principal_components))\n",
    "\n",
    "# 3) singular values are related to the eigenvalues of covariance matrix\n",
    "assert np.allclose((s ** 2) / (n - 1), l)\n",
    "\n",
    "# 8) dimensionality reduction\n",
    "k = 1\n",
    "PC_k = principal_components[:, 0:k]\n",
    "US_k = U[:, 0:k].dot(S[0:k, 0:k])\n",
    "print(PC_k, X[:,:])\n",
    "assert np.allclose(*flip_signs(PC_k, US_k))\n",
    "\n",
    "# 10) we used \"economy size\" (or \"thin\") SVD\n",
    "assert U.shape == (n, p)\n",
    "assert S.shape == (p, p)\n",
    "assert V.shape == (p, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
